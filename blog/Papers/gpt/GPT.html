<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>GPT：generative pre-training | LIANYONGXING. BLOG</title>
    <meta name="description" content="May the force be with u.">
    <meta name="generator" content="VuePress 1.4.0">
    <link rel="icon" href="ficon.jpeg">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/2.10.0/github-markdown.min.css">
    
    <link rel="preload" href="/assets/css/0.styles.a5323663.css" as="style"><link rel="preload" href="/assets/js/app.acaacfed.js" as="script"><link rel="preload" href="/assets/js/2.858fe96a.js" as="script"><link rel="preload" href="/assets/js/15.19b59d69.js" as="script"><link rel="prefetch" href="/assets/js/10.652038c7.js"><link rel="prefetch" href="/assets/js/100.2dd9d0f2.js"><link rel="prefetch" href="/assets/js/101.487a243a.js"><link rel="prefetch" href="/assets/js/102.0c61121f.js"><link rel="prefetch" href="/assets/js/103.4dbe63e3.js"><link rel="prefetch" href="/assets/js/104.7f502b03.js"><link rel="prefetch" href="/assets/js/105.6e83f9e6.js"><link rel="prefetch" href="/assets/js/106.5409dca1.js"><link rel="prefetch" href="/assets/js/107.7ad54acd.js"><link rel="prefetch" href="/assets/js/108.3486f36a.js"><link rel="prefetch" href="/assets/js/109.5ee4cd3b.js"><link rel="prefetch" href="/assets/js/11.4f8ea0df.js"><link rel="prefetch" href="/assets/js/110.6417250e.js"><link rel="prefetch" href="/assets/js/111.ded28c89.js"><link rel="prefetch" href="/assets/js/112.94f5b6c6.js"><link rel="prefetch" href="/assets/js/113.3b1fe42e.js"><link rel="prefetch" href="/assets/js/114.0e643f0c.js"><link rel="prefetch" href="/assets/js/115.32a16f28.js"><link rel="prefetch" href="/assets/js/12.a9ef9aaf.js"><link rel="prefetch" href="/assets/js/13.acff38a0.js"><link rel="prefetch" href="/assets/js/14.113e66b1.js"><link rel="prefetch" href="/assets/js/16.4ee77b14.js"><link rel="prefetch" href="/assets/js/17.a5b6d566.js"><link rel="prefetch" href="/assets/js/18.744a9950.js"><link rel="prefetch" href="/assets/js/19.fd9e7099.js"><link rel="prefetch" href="/assets/js/20.66903b5c.js"><link rel="prefetch" href="/assets/js/21.c98f5d06.js"><link rel="prefetch" href="/assets/js/22.a0056c91.js"><link rel="prefetch" href="/assets/js/23.73369199.js"><link rel="prefetch" href="/assets/js/24.dc5b3fc5.js"><link rel="prefetch" href="/assets/js/25.bf612edb.js"><link rel="prefetch" href="/assets/js/26.b9dd7686.js"><link rel="prefetch" href="/assets/js/27.371379cd.js"><link rel="prefetch" href="/assets/js/28.4a33fe83.js"><link rel="prefetch" href="/assets/js/29.be42af3d.js"><link rel="prefetch" href="/assets/js/3.47952932.js"><link rel="prefetch" href="/assets/js/30.37bd8e9e.js"><link rel="prefetch" href="/assets/js/31.58f89f44.js"><link rel="prefetch" href="/assets/js/32.741f73e3.js"><link rel="prefetch" href="/assets/js/33.a9c7dcb5.js"><link rel="prefetch" href="/assets/js/34.c3f829b5.js"><link rel="prefetch" href="/assets/js/35.29c897d0.js"><link rel="prefetch" href="/assets/js/36.1e02f622.js"><link rel="prefetch" href="/assets/js/37.a1d23a14.js"><link rel="prefetch" href="/assets/js/38.06964860.js"><link rel="prefetch" href="/assets/js/39.384a454e.js"><link rel="prefetch" href="/assets/js/4.7feb14c8.js"><link rel="prefetch" href="/assets/js/40.c7e4dfb7.js"><link rel="prefetch" href="/assets/js/41.3e5c5125.js"><link rel="prefetch" href="/assets/js/42.dcf19498.js"><link rel="prefetch" href="/assets/js/43.54203bcb.js"><link rel="prefetch" href="/assets/js/44.9cccb36c.js"><link rel="prefetch" href="/assets/js/45.3ce2a56c.js"><link rel="prefetch" href="/assets/js/46.17aac222.js"><link rel="prefetch" href="/assets/js/47.57ed0257.js"><link rel="prefetch" href="/assets/js/48.8baebce7.js"><link rel="prefetch" href="/assets/js/49.7eb16be5.js"><link rel="prefetch" href="/assets/js/5.55c31470.js"><link rel="prefetch" href="/assets/js/50.06274b55.js"><link rel="prefetch" href="/assets/js/51.b50e24a8.js"><link rel="prefetch" href="/assets/js/52.7b92239f.js"><link rel="prefetch" href="/assets/js/53.fb7cbb6a.js"><link rel="prefetch" href="/assets/js/54.d047b5f1.js"><link rel="prefetch" href="/assets/js/55.6e2fd120.js"><link rel="prefetch" href="/assets/js/56.fa7ee707.js"><link rel="prefetch" href="/assets/js/57.31b7d0a7.js"><link rel="prefetch" href="/assets/js/58.80cddbc7.js"><link rel="prefetch" href="/assets/js/59.92b2b0f2.js"><link rel="prefetch" href="/assets/js/6.792ce084.js"><link rel="prefetch" href="/assets/js/60.9ab8e458.js"><link rel="prefetch" href="/assets/js/61.b3abbf87.js"><link rel="prefetch" href="/assets/js/62.2bde1ed2.js"><link rel="prefetch" href="/assets/js/63.39cf6423.js"><link rel="prefetch" href="/assets/js/64.c839079e.js"><link rel="prefetch" href="/assets/js/65.ea1754c1.js"><link rel="prefetch" href="/assets/js/66.802ec528.js"><link rel="prefetch" href="/assets/js/67.a30d6fff.js"><link rel="prefetch" href="/assets/js/68.d98ac090.js"><link rel="prefetch" href="/assets/js/69.083b1217.js"><link rel="prefetch" href="/assets/js/7.3964fa52.js"><link rel="prefetch" href="/assets/js/70.272720ba.js"><link rel="prefetch" href="/assets/js/71.386b54d7.js"><link rel="prefetch" href="/assets/js/72.005e615f.js"><link rel="prefetch" href="/assets/js/73.b1266355.js"><link rel="prefetch" href="/assets/js/74.9ab08f58.js"><link rel="prefetch" href="/assets/js/75.eefe4ff0.js"><link rel="prefetch" href="/assets/js/76.e4162716.js"><link rel="prefetch" href="/assets/js/77.e1ead4d7.js"><link rel="prefetch" href="/assets/js/78.ae9b9cc3.js"><link rel="prefetch" href="/assets/js/79.eeaf4627.js"><link rel="prefetch" href="/assets/js/8.5ccbfc45.js"><link rel="prefetch" href="/assets/js/80.0272858c.js"><link rel="prefetch" href="/assets/js/81.bbc0907f.js"><link rel="prefetch" href="/assets/js/82.4de7fcc4.js"><link rel="prefetch" href="/assets/js/83.2ad342e1.js"><link rel="prefetch" href="/assets/js/84.3398b3bb.js"><link rel="prefetch" href="/assets/js/85.be446d7c.js"><link rel="prefetch" href="/assets/js/86.1ef2094d.js"><link rel="prefetch" href="/assets/js/87.53795a29.js"><link rel="prefetch" href="/assets/js/88.1c3ba029.js"><link rel="prefetch" href="/assets/js/89.a4797bc8.js"><link rel="prefetch" href="/assets/js/9.1e695694.js"><link rel="prefetch" href="/assets/js/90.12ceffe8.js"><link rel="prefetch" href="/assets/js/91.40c9fc92.js"><link rel="prefetch" href="/assets/js/92.9648154b.js"><link rel="prefetch" href="/assets/js/93.d4e90cec.js"><link rel="prefetch" href="/assets/js/94.50b5eb64.js"><link rel="prefetch" href="/assets/js/95.9d54c125.js"><link rel="prefetch" href="/assets/js/96.fce496cb.js"><link rel="prefetch" href="/assets/js/97.86a56b4e.js"><link rel="prefetch" href="/assets/js/98.cf20fa6d.js"><link rel="prefetch" href="/assets/js/99.92c0c3e3.js">
    <link rel="stylesheet" href="/assets/css/0.styles.a5323663.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">LIANYONGXING. BLOG</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/index.html" class="nav-link">
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Blog" class="dropdown-title"><span class="title">Blog</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/NLP/" class="nav-link">
  NLP
</a></li><li class="dropdown-item"><!----> <a href="/blog/machineLearning/" class="nav-link">
  MachineLearning
</a></li><li class="dropdown-item"><!----> <a href="/blog/Papers/" class="nav-link router-link-active">
  Papers
</a></li><li class="dropdown-item"><!----> <a href="/blog/recommenderSystem/" class="nav-link">
  RecommenderSystem
</a></li><li class="dropdown-item"><!----> <a href="/blog/ObjectDetection/" class="nav-link">
  ObjectDetection
</a></li><li class="dropdown-item"><!----> <a href="/blog/os/" class="nav-link">
  OperatorSystem
</a></li><li class="dropdown-item"><!----> <a href="/blog/cookies/" class="nav-link">
  Cookies
</a></li></ul></div></div><div class="nav-item"><a href="https://github.com/lianyongxing" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="/about/" class="nav-link">
  About
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/index.html" class="nav-link">
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Blog" class="dropdown-title"><span class="title">Blog</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/NLP/" class="nav-link">
  NLP
</a></li><li class="dropdown-item"><!----> <a href="/blog/machineLearning/" class="nav-link">
  MachineLearning
</a></li><li class="dropdown-item"><!----> <a href="/blog/Papers/" class="nav-link router-link-active">
  Papers
</a></li><li class="dropdown-item"><!----> <a href="/blog/recommenderSystem/" class="nav-link">
  RecommenderSystem
</a></li><li class="dropdown-item"><!----> <a href="/blog/ObjectDetection/" class="nav-link">
  ObjectDetection
</a></li><li class="dropdown-item"><!----> <a href="/blog/os/" class="nav-link">
  OperatorSystem
</a></li><li class="dropdown-item"><!----> <a href="/blog/cookies/" class="nav-link">
  Cookies
</a></li></ul></div></div><div class="nav-item"><a href="https://github.com/lianyongxing" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="/about/" class="nav-link">
  About
</a></div> <!----></nav>  <ul class="sidebar-links"><li><a href="/blog/Papers/" class="sidebar-link">概述</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Transformer</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Bert</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>GPT</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/blog/Papers/gpt/GPT.html" class="active sidebar-link">GPT：generative pre-training</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/blog/Papers/gpt/GPT.html#background" class="sidebar-link">Background</a></li><li class="sidebar-sub-header"><a href="/blog/Papers/gpt/GPT.html#unsupervised-pre-training" class="sidebar-link">Unsupervised pre-training</a></li><li class="sidebar-sub-header"><a href="/blog/Papers/gpt/GPT.html#supervised-fine-tune" class="sidebar-link">Supervised fine-tune</a></li><li class="sidebar-sub-header"><a href="/blog/Papers/gpt/GPT.html#task-specific-input-transformations" class="sidebar-link">Task-specific input transformations</a></li><li class="sidebar-sub-header"><a href="/blog/Papers/gpt/GPT.html#跟gpt-1的不同" class="sidebar-link">跟GPT-1的不同</a></li><li class="sidebar-sub-header"><a href="/blog/Papers/gpt/GPT.html#datasets" class="sidebar-link">Datasets</a></li><li class="sidebar-sub-header"><a href="/blog/Papers/gpt/GPT.html#结果" class="sidebar-link">结果</a></li><li class="sidebar-sub-header"><a href="/blog/Papers/gpt/GPT.html#架构" class="sidebar-link">架构</a></li><li class="sidebar-sub-header"><a href="/blog/Papers/gpt/GPT.html#limitation" class="sidebar-link">Limitation</a></li></ul></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Roberta</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>ViT</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>MAE</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>MoCo</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Swin Transformer</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Transformer-XL</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Deberta</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>XLNet</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Clip</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>ViLT</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>InstructGPT</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>MultiModal-01</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>MultiModal-02</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="gpt：generative-pre-training"><a href="#gpt：generative-pre-training" class="header-anchor">#</a> GPT：generative pre-training</h1> <h1 id="gpt-1"><a href="#gpt-1" class="header-anchor">#</a> <strong>GPT-1</strong></h1> <h2 id="background"><a href="#background" class="header-anchor">#</a> Background</h2> <p><strong>Improving language understanding by generative pre-training</strong></p> <ol><li>Radford A, Narasimhan K, Salimans T, et al. Improving language understanding by generative pre-training[J]. 2018.
<ol><li>无标注的数据有很多，标注数据很少，因此本文是通过无标注数据预训练，然后在有标注数据上微调</li> <li>之前的方法都是学词向量，但是遇到不同任务时，还要做不同的下游模型，这里作者统一用transformer的decoder结构，只需要改变输入格式就能应对不同任务，无需再改模型结构</li> <li>当时的困难有两个，一是不清楚用什么目标函数，虽然有LM、QA等各种任务，但是往往一种方式在另一个任务上效果就不太好了，没有一个统一好的目标函数；二是如何选择一种有效的将学习到的表征迁移到子任务上；</li></ol></li></ol> <p>作者最终选择了Transformer作为基础架构，因为发现transformer在不同任务的迁移学习上更robust，原因是其结构化的记忆模块能够处理更长的文本信息</p> <h2 id="unsupervised-pre-training"><a href="#unsupervised-pre-training" class="header-anchor">#</a> Unsupervised pre-training</h2> <p>GPT使用标准的语言模型在无标注的数据上进行预训练，极大化似然函数（已知前k-1时刻的值，预测k时刻的值），可以如下表示，U为窗口内的所有词，乘一个W参数，加上一个位置权重W，然后一起通过transformer block，得到一个输出<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">h_l</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.01968em;">l</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>，把这个输出乘上一个参数矩阵W，最后softmax，结果就是当前时刻值的概率分布</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mn>0</mn></msub><mo>=</mo><mi>U</mi><msub><mi>W</mi><mi>e</mi></msub><mo>+</mo><msub><mi>W</mi><mi>P</mi></msub></mrow><annotation encoding="application/x-tex">h_0 = UW_e + W_P
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.10903em;">U</span><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">e</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">+</span><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span></p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mi>l</mi></msub><mo>=</mo><mi>t</mi><mi>r</mi><mi>a</mi><mi>n</mi><mi>s</mi><mi>f</mi><mi>o</mi><mi>r</mi><mi>m</mi><mi>e</mi><msub><mi>r</mi><mrow><mi>b</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi></mrow></msub><mo>(</mo><msub><mi>h</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">h_l = transformer_{block}(h_{l-1})
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.01968em;">l</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathit">t</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">a</span><span class="mord mathit">n</span><span class="mord mathit">s</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">m</span><span class="mord mathit">e</span><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02778em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">b</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord mathit">c</span><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span></span></p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>u</mi><mo>)</mo><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo>(</mo><msub><mi>h</mi><mi>n</mi></msub><msubsup><mi>W</mi><mi>e</mi><mi>T</mi></msubsup><mo>)</mo></mrow><annotation encoding="application/x-tex">P(u) = softmax(h_nW_e^T)
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.8913309999999999em;"></span><span class="strut bottom" style="height:1.1413309999999999em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathit">u</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathit">s</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mord mathit">t</span><span class="mord mathit">m</span><span class="mord mathit">a</span><span class="mord mathit">x</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">n</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.247em;margin-left:-0.13889em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">e</span></span></span><span style="top:-0.4129999999999999em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">T</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span></span></p> <p><strong>这里跟Bert的区别是，bert是有掩码的语言模型（MLM），在预测其中某个词的时候可以看到整个句子；而GPT是标准语言模型，预测当前词的时候，只能看见之前的词，后面的词模型看不到；</strong></p> <p>（<strong>因此GPT是完全的预测未来，难度比bert高很多，bert相当于完形填空）</strong></p> <h2 id="supervised-fine-tune"><a href="#supervised-fine-tune" class="header-anchor">#</a> Supervised fine-tune</h2> <p>微调的时候是有标号的，每次给一个序列，预测y；实际上作者在微调的时候发现，将目标函数设置为一起预测标号和预测下一个词，效果更好</p> <p>微调的目标函数确定好之后，下一个问题就是如何将不同任务统一为这种形式：<strong>有标号的数据和对应的标号y</strong></p> <h2 id="task-specific-input-transformations"><a href="#task-specific-input-transformations" class="header-anchor">#</a> Task-specific input transformations</h2> <div align="center"><img src="/assets/img/Untitled.65a11103.png" width="100%"></div> <p>图1. 将不同任务统一为句子+label的形式</p> <p>图1展示了如何将不同任务统一形式输入模型做微调，<strong>核心实际上就是把不同文本串成一个序列</strong></p> <h1 id="gpt-2"><a href="#gpt-2" class="header-anchor">#</a> <strong>GPT-2</strong></h1> <p><strong>Language models are unsupervised multitask learners 语言模型是无监督的多任务学习器</strong></p> <ol><li>Liu, Pengfei, et al. &quot;Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing.&quot; <em>ACM Computing Surveys</em><br>
 55.9 (2023): 1-35.
<ol><li>gpt被bert打败了，因此想把模型做的更大，数据更多，构建了百万数据集WebText，模型变为15亿参数；但是仅仅加大模型和数据是不够的；</li> <li>当时业界主流是在一个数据集上训练好，然后去对应的任务上测试，因为模型的泛化性不太好；第二是当时有多任务学习（Multi-task learning）的方法，就是在多个数据集上一起训练，然后构造多个损失函数，可以提高点泛化性，但是这种方式在nlp上效果也一般，因为同样需要很多不同标注数据，而且也要微调</li> <li>因此作者提出了一个<strong>zero-shot</strong>的设定，就是只拼预训练，不需要下游任务的信息，直接做预测看效果，比模型的泛化能力</li></ol></li></ol> <h2 id="跟gpt-1的不同"><a href="#跟gpt-1的不同" class="header-anchor">#</a> 跟GPT-1的不同</h2> <p>因为不看下游fine-tune，没有标号数据了，因此要预测的东西和模式，必须在预训练的时候都加入，因此作者举了个例子，比如要进行翻译任务的时候，将输入设定为 (translate to french, english text, french text)，这样的话，再次进行翻译的时候，先输入模型一个translate to french，模型就能知道要翻译后面的东西了；再比如阅读理解的时候，输入为(answer the question, document,<br>
question, answer)，模型看到answer the question的时候就知道要回答问题了</p> <h2 id="datasets"><a href="#datasets" class="header-anchor">#</a> Datasets</h2> <p>爬取了大量数据，但是数据很脏，因此取了别人点赞数高的数据作为高质量数据</p> <h2 id="结果"><a href="#结果" class="header-anchor">#</a> 结果</h2> <div align="center"><img src="/assets/img/Untitled 1.16edad84.png" width="120%"></div> <p>图2. GPT-2在不同任务上的表现</p> <p>从结果上看，模型越大，效果越好，所以还是存在可能，<strong>把模型做的更大，理解能力更强的</strong></p> <h1 id="gpt-3"><a href="#gpt-3" class="header-anchor">#</a> GPT-3</h1> <p><strong>Language models are few-shot learners 语言模型是few-shot学习器</strong></p> <ol><li>Brown, Tom, et al. &quot;Language models are few-shot learners.&quot; <em>Advances in neural information processing systems</em> 33 (2020): 1877-1901.APA
<ol><li>GPT-2没有用任何下游数据finetune，GPT-3还是类似GPT-2的理念，不比微调，而是通过预训练来看模型的效果；但是实际上像人也是看到一些例子后，理解能力会更强，因此作者考虑用少量的数据来训练，也就是few-shot learning</li> <li><strong>大力出奇迹，搞了1750个亿参数的模型，模型大小和数据都是GPT-2的一百倍</strong></li> <li>提出个概念meta-learning和in-context learning</li></ol></li></ol> <div align="center"><img src="/assets/img/Untitled 2.1a2876b7.png" width="80%"></div> <p>图3. 在不同任务上的效果</p> <p><strong>在zero-shot、one-shot和few-shot上的不同效果，并且随着参数增加，效果一直提高；</strong></p> <div align="center"><img src="/assets/img/Untitled 3.3572a8bf.png" width="100%"></div> <p>图4. 不同任务是怎么做的</p> <p>在不同任务的时候，<strong>给了不同的任务提示</strong>，用“⇒”告诉模型可以输出了；每次不用给到的数据不参与微调模型的参数</p> <h2 id="架构"><a href="#架构" class="header-anchor">#</a> 架构</h2> <div align="center"><img src="/assets/img/Untitled 4.068cdaa5.png" width="100%"></div> <p>图5. 不同size的GPT</p> <p>架构跟GPT-2差不多，主要是加了层，其他的是用了sparse transformer的相似结构，用了pre-normalization</p> <div align="center"><img src="/assets/img/Untitled 5.f9a0534a.png" width="100%"></div> <p>图6. GPT3的数据集</p> <h2 id="limitation"><a href="#limitation" class="header-anchor">#</a> Limitation</h2> <ul><li>模型是真的学到了东西还是从大量数据中去检索到的</li> <li>对生成效果不太好</li> <li>训练太难了。。</li></ul> <h1 id="gpt-4"><a href="#gpt-4" class="header-anchor">#</a> GPT-4</h1> <p><a href="https://openai.com/research/gpt-4" target="_blank" rel="noopener noreferrer">GPT-4<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/blog/Papers/bert/BERT Pre-training of Deep Bidirectional Transformer.html" class="prev">
        BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
      </a></span> <span class="next"><a href="/blog/Papers/roberta/Roberta.html">
        Roberta: A robustly optimized bert pretraining approach
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.acaacfed.js" defer></script><script src="/assets/js/2.858fe96a.js" defer></script><script src="/assets/js/15.19b59d69.js" defer></script>
  </body>
</html>
