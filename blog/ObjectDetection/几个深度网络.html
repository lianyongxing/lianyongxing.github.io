<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>深度网络演进 | LIANYONGXING. BLOG</title>
    <meta name="description" content="May the force be with u.">
    <meta name="generator" content="VuePress 1.4.0">
    <link rel="icon" href="ficon.jpeg">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/2.10.0/github-markdown.min.css">
    
    <link rel="preload" href="/assets/css/0.styles.a5323663.css" as="style"><link rel="preload" href="/assets/js/app.acaacfed.js" as="script"><link rel="preload" href="/assets/js/2.858fe96a.js" as="script"><link rel="preload" href="/assets/js/4.7feb14c8.js" as="script"><link rel="prefetch" href="/assets/js/10.652038c7.js"><link rel="prefetch" href="/assets/js/100.2dd9d0f2.js"><link rel="prefetch" href="/assets/js/101.487a243a.js"><link rel="prefetch" href="/assets/js/102.0c61121f.js"><link rel="prefetch" href="/assets/js/103.4dbe63e3.js"><link rel="prefetch" href="/assets/js/104.7f502b03.js"><link rel="prefetch" href="/assets/js/105.6e83f9e6.js"><link rel="prefetch" href="/assets/js/106.5409dca1.js"><link rel="prefetch" href="/assets/js/107.7ad54acd.js"><link rel="prefetch" href="/assets/js/108.3486f36a.js"><link rel="prefetch" href="/assets/js/109.5ee4cd3b.js"><link rel="prefetch" href="/assets/js/11.4f8ea0df.js"><link rel="prefetch" href="/assets/js/110.6417250e.js"><link rel="prefetch" href="/assets/js/111.ded28c89.js"><link rel="prefetch" href="/assets/js/112.94f5b6c6.js"><link rel="prefetch" href="/assets/js/113.3b1fe42e.js"><link rel="prefetch" href="/assets/js/114.0e643f0c.js"><link rel="prefetch" href="/assets/js/115.32a16f28.js"><link rel="prefetch" href="/assets/js/12.a9ef9aaf.js"><link rel="prefetch" href="/assets/js/13.acff38a0.js"><link rel="prefetch" href="/assets/js/14.113e66b1.js"><link rel="prefetch" href="/assets/js/15.19b59d69.js"><link rel="prefetch" href="/assets/js/16.4ee77b14.js"><link rel="prefetch" href="/assets/js/17.a5b6d566.js"><link rel="prefetch" href="/assets/js/18.744a9950.js"><link rel="prefetch" href="/assets/js/19.fd9e7099.js"><link rel="prefetch" href="/assets/js/20.66903b5c.js"><link rel="prefetch" href="/assets/js/21.c98f5d06.js"><link rel="prefetch" href="/assets/js/22.a0056c91.js"><link rel="prefetch" href="/assets/js/23.73369199.js"><link rel="prefetch" href="/assets/js/24.dc5b3fc5.js"><link rel="prefetch" href="/assets/js/25.bf612edb.js"><link rel="prefetch" href="/assets/js/26.b9dd7686.js"><link rel="prefetch" href="/assets/js/27.371379cd.js"><link rel="prefetch" href="/assets/js/28.4a33fe83.js"><link rel="prefetch" href="/assets/js/29.be42af3d.js"><link rel="prefetch" href="/assets/js/3.47952932.js"><link rel="prefetch" href="/assets/js/30.37bd8e9e.js"><link rel="prefetch" href="/assets/js/31.58f89f44.js"><link rel="prefetch" href="/assets/js/32.741f73e3.js"><link rel="prefetch" href="/assets/js/33.a9c7dcb5.js"><link rel="prefetch" href="/assets/js/34.c3f829b5.js"><link rel="prefetch" href="/assets/js/35.29c897d0.js"><link rel="prefetch" href="/assets/js/36.1e02f622.js"><link rel="prefetch" href="/assets/js/37.a1d23a14.js"><link rel="prefetch" href="/assets/js/38.06964860.js"><link rel="prefetch" href="/assets/js/39.384a454e.js"><link rel="prefetch" href="/assets/js/40.c7e4dfb7.js"><link rel="prefetch" href="/assets/js/41.3e5c5125.js"><link rel="prefetch" href="/assets/js/42.dcf19498.js"><link rel="prefetch" href="/assets/js/43.54203bcb.js"><link rel="prefetch" href="/assets/js/44.9cccb36c.js"><link rel="prefetch" href="/assets/js/45.3ce2a56c.js"><link rel="prefetch" href="/assets/js/46.17aac222.js"><link rel="prefetch" href="/assets/js/47.57ed0257.js"><link rel="prefetch" href="/assets/js/48.8baebce7.js"><link rel="prefetch" href="/assets/js/49.7eb16be5.js"><link rel="prefetch" href="/assets/js/5.55c31470.js"><link rel="prefetch" href="/assets/js/50.06274b55.js"><link rel="prefetch" href="/assets/js/51.b50e24a8.js"><link rel="prefetch" href="/assets/js/52.7b92239f.js"><link rel="prefetch" href="/assets/js/53.fb7cbb6a.js"><link rel="prefetch" href="/assets/js/54.d047b5f1.js"><link rel="prefetch" href="/assets/js/55.6e2fd120.js"><link rel="prefetch" href="/assets/js/56.fa7ee707.js"><link rel="prefetch" href="/assets/js/57.31b7d0a7.js"><link rel="prefetch" href="/assets/js/58.80cddbc7.js"><link rel="prefetch" href="/assets/js/59.92b2b0f2.js"><link rel="prefetch" href="/assets/js/6.792ce084.js"><link rel="prefetch" href="/assets/js/60.9ab8e458.js"><link rel="prefetch" href="/assets/js/61.b3abbf87.js"><link rel="prefetch" href="/assets/js/62.2bde1ed2.js"><link rel="prefetch" href="/assets/js/63.39cf6423.js"><link rel="prefetch" href="/assets/js/64.c839079e.js"><link rel="prefetch" href="/assets/js/65.ea1754c1.js"><link rel="prefetch" href="/assets/js/66.802ec528.js"><link rel="prefetch" href="/assets/js/67.a30d6fff.js"><link rel="prefetch" href="/assets/js/68.d98ac090.js"><link rel="prefetch" href="/assets/js/69.083b1217.js"><link rel="prefetch" href="/assets/js/7.3964fa52.js"><link rel="prefetch" href="/assets/js/70.272720ba.js"><link rel="prefetch" href="/assets/js/71.386b54d7.js"><link rel="prefetch" href="/assets/js/72.005e615f.js"><link rel="prefetch" href="/assets/js/73.b1266355.js"><link rel="prefetch" href="/assets/js/74.9ab08f58.js"><link rel="prefetch" href="/assets/js/75.eefe4ff0.js"><link rel="prefetch" href="/assets/js/76.e4162716.js"><link rel="prefetch" href="/assets/js/77.e1ead4d7.js"><link rel="prefetch" href="/assets/js/78.ae9b9cc3.js"><link rel="prefetch" href="/assets/js/79.eeaf4627.js"><link rel="prefetch" href="/assets/js/8.5ccbfc45.js"><link rel="prefetch" href="/assets/js/80.0272858c.js"><link rel="prefetch" href="/assets/js/81.bbc0907f.js"><link rel="prefetch" href="/assets/js/82.4de7fcc4.js"><link rel="prefetch" href="/assets/js/83.2ad342e1.js"><link rel="prefetch" href="/assets/js/84.3398b3bb.js"><link rel="prefetch" href="/assets/js/85.be446d7c.js"><link rel="prefetch" href="/assets/js/86.1ef2094d.js"><link rel="prefetch" href="/assets/js/87.53795a29.js"><link rel="prefetch" href="/assets/js/88.1c3ba029.js"><link rel="prefetch" href="/assets/js/89.a4797bc8.js"><link rel="prefetch" href="/assets/js/9.1e695694.js"><link rel="prefetch" href="/assets/js/90.12ceffe8.js"><link rel="prefetch" href="/assets/js/91.40c9fc92.js"><link rel="prefetch" href="/assets/js/92.9648154b.js"><link rel="prefetch" href="/assets/js/93.d4e90cec.js"><link rel="prefetch" href="/assets/js/94.50b5eb64.js"><link rel="prefetch" href="/assets/js/95.9d54c125.js"><link rel="prefetch" href="/assets/js/96.fce496cb.js"><link rel="prefetch" href="/assets/js/97.86a56b4e.js"><link rel="prefetch" href="/assets/js/98.cf20fa6d.js"><link rel="prefetch" href="/assets/js/99.92c0c3e3.js">
    <link rel="stylesheet" href="/assets/css/0.styles.a5323663.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">LIANYONGXING. BLOG</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/index.html" class="nav-link">
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Blog" class="dropdown-title"><span class="title">Blog</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/NLP/" class="nav-link">
  NLP
</a></li><li class="dropdown-item"><!----> <a href="/blog/machineLearning/" class="nav-link">
  MachineLearning
</a></li><li class="dropdown-item"><!----> <a href="/blog/Papers/" class="nav-link">
  Papers
</a></li><li class="dropdown-item"><!----> <a href="/blog/recommenderSystem/" class="nav-link">
  RecommenderSystem
</a></li><li class="dropdown-item"><!----> <a href="/blog/ObjectDetection/" class="nav-link router-link-active">
  ObjectDetection
</a></li><li class="dropdown-item"><!----> <a href="/blog/os/" class="nav-link">
  OperatorSystem
</a></li><li class="dropdown-item"><!----> <a href="/blog/cookies/" class="nav-link">
  Cookies
</a></li></ul></div></div><div class="nav-item"><a href="https://github.com/lianyongxing" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="/about/" class="nav-link">
  About
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/index.html" class="nav-link">
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Blog" class="dropdown-title"><span class="title">Blog</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/NLP/" class="nav-link">
  NLP
</a></li><li class="dropdown-item"><!----> <a href="/blog/machineLearning/" class="nav-link">
  MachineLearning
</a></li><li class="dropdown-item"><!----> <a href="/blog/Papers/" class="nav-link">
  Papers
</a></li><li class="dropdown-item"><!----> <a href="/blog/recommenderSystem/" class="nav-link">
  RecommenderSystem
</a></li><li class="dropdown-item"><!----> <a href="/blog/ObjectDetection/" class="nav-link router-link-active">
  ObjectDetection
</a></li><li class="dropdown-item"><!----> <a href="/blog/os/" class="nav-link">
  OperatorSystem
</a></li><li class="dropdown-item"><!----> <a href="/blog/cookies/" class="nav-link">
  Cookies
</a></li></ul></div></div><div class="nav-item"><a href="https://github.com/lianyongxing" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="/about/" class="nav-link">
  About
</a></div> <!----></nav>  <ul class="sidebar-links"><li><a href="/blog/ObjectDetection/" class="sidebar-link">概述</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>目标检测常见指标</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>优化器(Optimizer)</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>深度网络发展&amp;演进</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/blog/ObjectDetection/几个深度网络.html" class="active sidebar-link">深度网络演进</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/blog/ObjectDetection/几个深度网络.html#alexnet" class="sidebar-link">AlexNet</a></li><li class="sidebar-sub-header"><a href="/blog/ObjectDetection/几个深度网络.html#vgg" class="sidebar-link">VGG</a></li><li class="sidebar-sub-header"><a href="/blog/ObjectDetection/几个深度网络.html#googlenet" class="sidebar-link">GoogLeNet</a></li><li class="sidebar-sub-header"><a href="/blog/ObjectDetection/几个深度网络.html#resnet" class="sidebar-link">ResNet</a></li><li class="sidebar-sub-header"><a href="/blog/ObjectDetection/几个深度网络.html#mobilenet" class="sidebar-link">MobileNet</a></li><li class="sidebar-sub-header"><a href="/blog/ObjectDetection/几个深度网络.html#迁移学习" class="sidebar-link">迁移学习</a></li></ul></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Faster RCNN合集</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>SSD</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>尺度不变性变换(SIFT)</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="深度网络演进"><a href="#深度网络演进" class="header-anchor">#</a> 深度网络演进</h1> <div align="center"><img src="/assets/img/FAB60E2A-0C7B-498D-A46F-E14C92C811CA.cd72743c.jpg" width="80%"></div> <p>最早的深度网络，仅包含各个普通的层的CNN，卷积层，激活函数，池化层，全连接层</p> <h2 id="alexnet"><a href="#alexnet" class="header-anchor">#</a> AlexNet</h2> <div align="center"><img src="/assets/img/E6731EFB-9547-44E5-B859-2DDAEEFAFBDA.4247ec87.png" width="80%"></div> <p>Alexnet是2012的ISLVRC冠军，准确率由70%提高到80%左右，使用GPU训练</p> <h3 id="主要亮点"><a href="#主要亮点" class="header-anchor">#</a> 主要亮点</h3> <ul><li>使用GPU训练</li> <li>使用了Relu函数</li> <li>使用了LRN局部响应归一化</li> <li>在全连阶层使用dropout随机失活神经元，以减少过拟合</li></ul> <h2 id="vgg"><a href="#vgg" class="header-anchor">#</a> VGG</h2> <div align="center"><img src="/assets/img/6337EABA-A6AA-4B8F-B007-D52C3F39DC33.2329cd01.png" width="66%"></div> <p>2014年推出，ImageNet获奖</p> <p>网络中的亮点，通过堆叠多个3x3的卷积核来代替大尺度卷积核（减少所需的参数），从而使网络层次更深</p> <p>可以使用堆叠2个3x3的卷积核来替代5x5的卷积核，堆叠3个3x3的卷积核来替代7x7的卷积核。（具有相同的感受野）</p> <p>感受野计算公式：</p> <p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>R</mi><msub><mi>F</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>R</mi><msub><mi>F</mi><mrow><mi>i</mi></mrow></msub><mo>+</mo><mo>(</mo><mi>k</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>−</mo><mn>1</mn><mo>)</mo><mo>∗</mo><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">RF_{i+1} = RF_{i}+(ksize-1)*stride</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span><span class="mbin">+</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">+</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="mord mathit">s</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.04398em;">z</span><span class="mord mathit">e</span><span class="mbin">−</span><span class="mord mathrm">1</span><span class="mclose">)</span><span class="mbin">∗</span><span class="mord mathit">s</span><span class="mord mathit">t</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">i</span><span class="mord mathit">d</span><span class="mord mathit">e</span></span></span></span></p> <p>第一层 1</p> <p>第二层 （F(1)-1）*stride + ksize</p> <p>第三层 （F(2)-1）*stride + ksize</p> <p>第n层 （F(n-1)-1）*stride + ksize</p> <p>感受野的概念</p> <div align="center"><img src="/assets/img/D3801086-0F96-454C-A6AE-C49AE96FAF25.197bd431.png" width="75%"></div> <h2 id="googlenet"><a href="#googlenet" class="header-anchor">#</a> GoogLeNet</h2> <ul><li>引入了Inception结构</li> <li>使用1x1卷积核进行降维以及映射处理</li> <li>添加两个辅助分类器进行训练</li> <li>丢弃全连接层，使用平均池化层（大大减少模型参数）</li></ul> <h3 id="inception结构"><a href="#inception结构" class="header-anchor">#</a> Inception结构</h3> <p>初始的Inception结构</p> <div align="center"><img src="/assets/img/AEA09B74-A0E3-45C8-B952-30B218BD5729.91514c91.png" width="60%"></div> <p>不同分支得到不同尺度的特征矩阵，每个分支得到的特征矩阵的高和宽必须相同（在深度上进行拼接）</p> <p>添加了降维模块的Inception结构<br></p><div align="center"><br> <img src="/assets/img/43AD0168-8096-4E9F-87B0-BB1CFCF1BE42.3adeff9c.png" width="60%"><br></div><p></p> <p>使用1x1的卷积核进行降维，降维可以抽取特征点和主要特征</p> <h3 id="辅助分类器"><a href="#辅助分类器" class="header-anchor">#</a> 辅助分类器</h3> <p>在中间输出层接一个分类器，作为辅助分类，因此在训练的时候有3个loss</p> <h2 id="resnet"><a href="#resnet" class="header-anchor">#</a> ResNet</h2> <p>Resnet2015年提出，ImageNet第一名</p> <p>网络亮点</p> <ul><li>超深的网络结构（突破1000层）</li> <li>提出残差模块</li> <li>使用batchnormal加速训练（丢弃dropout）</li></ul> <p>过深的网络</p> <ul><li>存在梯度消失和梯度爆炸（梯度剪切/正则、激活函数、BN、预训练微调，残差网络，LSTM）</li> <li>退化问题</li></ul> <h3 id="残差模块"><a href="#残差模块" class="header-anchor">#</a> 残差模块</h3> <div align="center"><img src="/assets/img/562460D0-8FCF-47A7-9BA7-A2205AAC12C5.c4345f2a.png" width="60%"></div> <p>主分支与shortcut输出特征矩阵的shape必须相同，因此如果是虚线的话，就是先做一个变维操作，再进行结合。</p> <p>残差一半比较小，学习残差难度小一点</p> <div align="center"><img src="/assets/img/D415D4B8-A105-4B15-BEF5-4C57069EDE79.ca4a2f0d.png" width="60%"></div> <p>这个操作可以使得低维的信息为高维的信息做一个补充，并且防止梯度消失</p> <h3 id="batchnorm"><a href="#batchnorm" class="header-anchor">#</a> BatchNorm</h3> <p>在图像输入时，一般会对图像进行标准化处理，这样能加速网络的收敛，对于第一个conv层，输入是满足某个分布的特征矩阵，但其输出就变了，作为下一个conv的输入时，不满足某个分布规律了（这里指的是整个训练样本集对应的feature map的数据要满足的分布规律）。而batchnorm就是使feature map满足均值为0，方差为1的分布律。</p> <div align="center"><img src="/assets/img/AAC8ED85-A88E-436F-8D94-B05F01590AC5.ae626181.png" width="80%"></div> <p>对于一批数据，计算均值和方差，然后将数据进行归一化，归一化后再用两个参数进行线性调节，因为均值为0，方差为1的数据的效果不一定是最好的，这两个参数是通过反向传播进行学习得到的。</p> <h4 id="bn需要注意的问题"><a href="#bn需要注意的问题" class="header-anchor">#</a> BN需要注意的问题</h4> <ul><li>训练时将traing设置为True，验证时设置为False</li> <li>batchsize设置的尽可能大，在小的时候表现不好，设置大的求的的均值和方差接近整个训练集的均值和方差</li> <li>论文中建议将BN层放在Conv和激活函数之间，且卷积层不要使用bias，因为没有用（调整后的值和调整前的值一样）</li></ul> <p>因为输出如果有bias，则归一化的时候减去均值时，也会有bias，两者抵消，而方差相同，因此输出相同。</p> <h2 id="mobilenet"><a href="#mobilenet" class="header-anchor">#</a> MobileNet</h2> <p>mobilenet是2017年提出的，专注于移动端或者嵌入式设备中的轻量CNN网络，准确率小幅度降低的情况下大大减少了模型参数的运算量</p> <p>网络亮点</p> <ul><li>Depthwise Convolution（大大减少运算量和参数数量）DW卷积</li> <li>增加超参数 控制卷积核的个数的参数alpha，控制输入图像大小的beta</li></ul> <h4 id="dw卷积（depthwise-conv）"><a href="#dw卷积（depthwise-conv）" class="header-anchor">#</a> DW卷积（Depthwise Conv）</h4> <p>卷积核channel = 1（每个卷积核负责1个channel ）</p> <p>输入特征矩阵channel = 卷积核个数 = 输出特征矩阵channel</p> <h4 id="深度可分的卷积（depthwise-separable-conv）"><a href="#深度可分的卷积（depthwise-separable-conv）" class="header-anchor">#</a> 深度可分的卷积（Depthwise Separable Conv）</h4> <p>由DW卷积（DepthWise）和PW卷积（PointsWise）组成</p> <p>PW卷积就是普通卷积，只不过尺寸是1x1</p> <div align="center"><img src="/assets/img/image-20200707160115010.d6ee5bf6.png" width="80%"></div> <h3 id="mobilenet-v1"><a href="#mobilenet-v1" class="header-anchor">#</a> MobileNet v1</h3> <p>v1版本集成了DW卷积和PW卷积，引入两个参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>控制卷积核的个数，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.05278em;">β</span></span></span></span>控制输入图片的size，虽然在精度上有一点下降，但是大大降低了模型参数和计算量，但在实际训练的时候，发现depthwise部分卷积核会被废掉，即卷积核参数大部分为0，这个在v2版本进行了改善</p> <h3 id="mobilenet-v2"><a href="#mobilenet-v2" class="header-anchor">#</a> MobileNet v2</h3> <p>相比v1准确率更高，模型更小。</p> <p>亮点主要有两个：</p> <ul><li>Inverted Residual block（倒残差结构）</li> <li>Linear Bottlenecks</li></ul> <p>回顾：残差结构将输入通过1x1的卷积核，降低输入特征的channel，然后正常卷积，最后再通过一个1x1的卷积核扩充channnl，即步骤包括1x1降维、卷积、1x1升维。</p> <p>A. 倒残差结构</p> <p>先通过一个1x1的卷积核实现channel升维，再通过3x3的DW卷积，最后通过1x1的卷积核channel降维，正好跟残差结构是相反的，因此叫倒残差结构。需要注意的是，在普通残差网络中，激活函数为RELU，而在倒残差结构中，使用的激活函数为RELU6</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>R</mi><mi>e</mi><mi>l</mi><mi>u</mi><mn>6</mn><mo>=</mo><mi>m</mi><mi>i</mi><mi>n</mi><mo>(</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mn>0</mn><mo>)</mo><mo separator="true">,</mo><mn>6</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">Relu6 = min(max(x, 0), 6)
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">u</span><span class="mord mathrm">6</span><span class="mrel">=</span><span class="mord mathit">m</span><span class="mord mathit">i</span><span class="mord mathit">n</span><span class="mopen">(</span><span class="mord mathit">m</span><span class="mord mathit">a</span><span class="mord mathit">x</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mpunct">,</span><span class="mord mathrm">0</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mord mathrm">6</span><span class="mclose">)</span></span></span></span></span></p> <div align="center"><img src="/assets/img/image-20200707161443093.dab6d58b.png" width="80%"></div> <p>B. linear Bottlenecks</p> <p>对于倒残差结构中最后一个1x1的卷积层，采用了线性激活函数，而非RELU，原论文中，RELU对低维特征信息造成较大损失。</p> <p>作者在论文中做了一个实验，用一个单通道的图片作为输入，然后用多层矩阵<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">T</span></span></span></span>作卷积进行特征提取，提取高维特征后，用RELU输出，然后再用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>T</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">T^{-1}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">T</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>进行反变换，企图得到最初的输入。当提取2、3层时，发现做反变换后，得到的输出图像相对于输入图像有很大的缺失，而提取到10层以上的时候，才可以相对完整的还原出原始图像，因此觉得RELU对低维的信息会产生损失。而由于倒残差结构两边细，中间粗的结构，输出的是一个低维的信息，因此不使用RELU激活函数，而使用线性激活函数。<br></p><div align="center"><br> <img src="/assets/img/image-20200707162734216.e74fe279.png" width="80%"><br></div><p></p> <p>注意：在倒残差结构中，只有输入stride为1，而且输入特征矩阵和输出特征矩阵shape相等的时候才有shortcut连接</p> <h2 id="迁移学习"><a href="#迁移学习" class="header-anchor">#</a> 迁移学习</h2> <div align="center"><img src="/assets/img/77A11318-0284-435C-8780-35AF0B36E9F0.132020ab.png" width="80%"></div></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/blog/ObjectDetection/优化器.html" class="prev">
        优化器(Optimizer)
      </a></span> <span class="next"><a href="/blog/ObjectDetection/目标检测网络.html">
        Faster RCNN合集
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.acaacfed.js" defer></script><script src="/assets/js/2.858fe96a.js" defer></script><script src="/assets/js/4.7feb14c8.js" defer></script>
  </body>
</html>
