(window.webpackJsonp=window.webpackJsonp||[]).push([[64],{541:function(t,s,a){t.exports=a.p+"assets/img/909649E9-ABB3-45ED-86A1-D8FE1866473C.c4d0d37b.png"},705:function(t,s,a){"use strict";a.r(s);var n=a(44),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"决策树应用（sklearn）"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#决策树应用（sklearn）"}},[t._v("#")]),t._v(" 决策树应用（sklearn）")]),t._v(" "),n("h2",{attrs:{id:"问题说明"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#问题说明"}},[t._v("#")]),t._v(" 问题说明")]),t._v(" "),n("p",[t._v("对于一个人是否购买电子产品，有age、income、student、credit_rating几个影响因素，根据这些影响因素拟合出一棵决策树，并进行预测。")]),t._v(" "),n("table",[n("thead",[n("tr",[n("th",[t._v("RID")]),t._v(" "),n("th",[t._v("age")]),t._v(" "),n("th",[t._v("income")]),t._v(" "),n("th",[t._v("student")]),t._v(" "),n("th",[t._v("credit_rating")]),t._v(" "),n("th",[t._v("class_buys_computer")])])]),t._v(" "),n("tbody",[n("tr",[n("td",[t._v("1")]),t._v(" "),n("td",[t._v("youth")]),t._v(" "),n("td",[t._v("high")]),t._v(" "),n("td",[t._v("no")]),t._v(" "),n("td",[t._v("fair")]),t._v(" "),n("td",[t._v("no")])]),t._v(" "),n("tr",[n("td",[t._v("2")]),t._v(" "),n("td",[t._v("youth")]),t._v(" "),n("td",[t._v("high")]),t._v(" "),n("td",[t._v("no")]),t._v(" "),n("td",[t._v("excellent")]),t._v(" "),n("td",[t._v("no")])]),t._v(" "),n("tr",[n("td",[t._v("3")]),t._v(" "),n("td",[t._v("middle_aged")]),t._v(" "),n("td",[t._v("high")]),t._v(" "),n("td",[t._v("no")]),t._v(" "),n("td",[t._v("fair")]),t._v(" "),n("td",[t._v("yes")])]),t._v(" "),n("tr",[n("td",[t._v("4")]),t._v(" "),n("td",[t._v("senior")]),t._v(" "),n("td",[t._v("medium")]),t._v(" "),n("td",[t._v("no")]),t._v(" "),n("td",[t._v("fair")]),t._v(" "),n("td",[t._v("yes")])]),t._v(" "),n("tr",[n("td",[t._v("5")]),t._v(" "),n("td",[t._v("senior")]),t._v(" "),n("td",[t._v("low")]),t._v(" "),n("td",[t._v("yes")]),t._v(" "),n("td",[t._v("fair")]),t._v(" "),n("td",[t._v("yes")])]),t._v(" "),n("tr",[n("td",[t._v("6")]),t._v(" "),n("td",[t._v("senior")]),t._v(" "),n("td",[t._v("low")]),t._v(" "),n("td",[t._v("yes")]),t._v(" "),n("td",[t._v("excellent")]),t._v(" "),n("td",[t._v("no")])]),t._v(" "),n("tr",[n("td",[t._v("7")]),t._v(" "),n("td",[t._v("middle_aged")]),t._v(" "),n("td",[t._v("low")]),t._v(" "),n("td",[t._v("yes")]),t._v(" "),n("td",[t._v("excellent")]),t._v(" "),n("td",[t._v("yes")])]),t._v(" "),n("tr",[n("td",[t._v("8")]),t._v(" "),n("td",[t._v("youth")]),t._v(" "),n("td",[t._v("medium")]),t._v(" "),n("td",[t._v("no")]),t._v(" "),n("td",[t._v("fair")]),t._v(" "),n("td",[t._v("no")])]),t._v(" "),n("tr",[n("td",[t._v("9")]),t._v(" "),n("td",[t._v("youth")]),t._v(" "),n("td",[t._v("low")]),t._v(" "),n("td",[t._v("yes")]),t._v(" "),n("td",[t._v("fair")]),t._v(" "),n("td",[t._v("yes")])]),t._v(" "),n("tr",[n("td",[t._v("10")]),t._v(" "),n("td",[t._v("senior")]),t._v(" "),n("td",[t._v("medium")]),t._v(" "),n("td",[t._v("yes")]),t._v(" "),n("td",[t._v("fair")]),t._v(" "),n("td",[t._v("yes")])]),t._v(" "),n("tr",[n("td",[t._v("11")]),t._v(" "),n("td",[t._v("youth")]),t._v(" "),n("td",[t._v("medium")]),t._v(" "),n("td",[t._v("yes")]),t._v(" "),n("td",[t._v("excellent")]),t._v(" "),n("td",[t._v("yes")])]),t._v(" "),n("tr",[n("td",[t._v("12")]),t._v(" "),n("td",[t._v("middle_aged")]),t._v(" "),n("td",[t._v("medium")]),t._v(" "),n("td",[t._v("no")]),t._v(" "),n("td",[t._v("excellent")]),t._v(" "),n("td",[t._v("yes")])]),t._v(" "),n("tr",[n("td",[t._v("13")]),t._v(" "),n("td",[t._v("middle_aged")]),t._v(" "),n("td",[t._v("high")]),t._v(" "),n("td",[t._v("yes")]),t._v(" "),n("td",[t._v("fair")]),t._v(" "),n("td",[t._v("yes")])]),t._v(" "),n("tr",[n("td",[t._v("14")]),t._v(" "),n("td",[t._v("senior")]),t._v(" "),n("td",[t._v("medium")]),t._v(" "),n("td",[t._v("no")]),t._v(" "),n("td",[t._v("excellent")]),t._v(" "),n("td",[t._v("no")])])])]),t._v(" "),n("h2",{attrs:{id:"pythoncode"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#pythoncode"}},[t._v("#")]),t._v(" PythonCode")]),t._v(" "),n("h3",{attrs:{id:"导入sklearn相关库"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#导入sklearn相关库"}},[t._v("#")]),t._v(" 导入sklearn相关库")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" sklearn\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" csv\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("feature_extraction "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" DictVectorizer\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" preprocessing\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tree\n")])])]),n("h3",{attrs:{id:"导入csv文件，读取原始数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#导入csv文件，读取原始数据"}},[t._v("#")]),t._v(" 导入csv文件，读取原始数据")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("r'/Users/lianyongxing/Desktop/machineLearning/decisionTree/src/AllElectronics.csv'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'rt'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nreader "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" csv"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reader"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#按行读取")]),t._v("\nheaders "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("next")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("reader"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nfeatureList "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nlabelList "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" row "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" reader"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    labelList"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    rowDict "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("headers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        rowDict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("headers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),n("h3",{attrs:{id:"数据格式转化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#数据格式转化"}},[t._v("#")]),t._v(" 数据格式转化")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 字典的向量化")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这个过程将原始数据中的属性值youth、high、no等数据转化为sklearn可识别的0、1；将原始数据中的标签yes、no转化为sklearn可识别的0、1")]),t._v("\nvec "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DictVectorizer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndummyX "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" vec"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_transform"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("featureList"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toarray"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# # print(dummyX)")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ")]),t._v("\ndummyY "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" preprocessing"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("label_binarize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("labelList"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("classes"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'no'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'yes'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# # print(dummyY)")]),t._v("\n")])])]),n("h3",{attrs:{id:"构造决策树"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#构造决策树"}},[t._v("#")]),t._v(" 构造决策树")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据数据构造决策树")]),t._v("\nclf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tree"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DecisionTreeClassifier"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("criterion"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'entropy'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nclf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" clf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dummyX"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dummyY"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h3",{attrs:{id:"输出结果"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#输出结果"}},[t._v("#")]),t._v(" 输出结果")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将输出的结果保存为dot文件，后续用graphviz程序打开")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"output.dot"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'w'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    f "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tree"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("export_graphviz"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("clf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" feature_names"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("vec"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_feature_names"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" out_file"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" f"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h3",{attrs:{id:"可视化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#可视化"}},[t._v("#")]),t._v(" 可视化")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("# 在终端中将dot文件转换为可视化的pdf文件\ndot -T pdf output.dot -o output.pdf\n")])])]),n("h3",{attrs:{id:"结果"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#结果"}},[t._v("#")]),t._v(" 结果")]),t._v(" "),n("p",[t._v("得到的决策树如下所示")]),t._v(" "),n("p",[n("img",{attrs:{src:a(541),alt:"c4d0d37beb671b662b11de8aaaa17698"}})]),t._v(" "),n("p",[t._v("从中可以直观看出每一层的熵值和分类情况")]),t._v(" "),n("h3",{attrs:{id:"预测"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#预测"}},[t._v("#")]),t._v(" 预测")]),t._v(" "),n("p",[t._v("之后根据拟合好的决策树对新数据进行预测")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 在这里取了原始数据的第一行，然后把第一列和低4列的值修改了一下，作为新的输入")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 然后用决策树进行预测，得到predictY ")]),t._v("\noneRowX "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dummyX"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"oneRowX:"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("oneRowX"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nnewRowX "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" oneRowX\nnewRowX"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\nnewRowX"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n\npredictedY "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" clf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("newRowX"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);