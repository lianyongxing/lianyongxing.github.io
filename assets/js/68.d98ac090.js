(window.webpackJsonp=window.webpackJsonp||[]).push([[68],{621:function(t,s,a){t.exports=a.p+"assets/img/image-20200906125933259.197d7209.png"},734:function(t,s,a){"use strict";a.r(s);var n=a(44),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"tf-idf"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#tf-idf"}},[t._v("#")]),t._v(" TF-IDF")]),t._v(" "),n("p",[t._v("词频-逆文档频率（Term Frequency-Inverse Document Frequency，TF-IDF）是一种用于资讯检索和文本挖掘的常用加权技术")]),t._v(" "),n("p",[t._v("TF-IDF是一种统计方法，用以评估一个词对于一个文件集或者一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降")]),t._v(" "),n("p",[n("span",{staticClass:"katex-display"},[n("span",{staticClass:"katex"},[n("span",{staticClass:"katex-mathml"},[n("math",[n("semantics",[n("mrow",[n("mi",[t._v("T")]),n("mi",[t._v("F")]),n("mo",[t._v("−")]),n("mi",[t._v("I")]),n("mi",[t._v("D")]),n("mi",[t._v("F")]),n("mo",[t._v("=")]),n("mi",[t._v("T")]),n("mi",[t._v("F")]),n("mo",[t._v("∗")]),n("mi",[t._v("I")]),n("mi",[t._v("D")]),n("mi",[t._v("F")])],1),n("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("TF-IDF = TF * IDF\n")])],1)],1)],1),n("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[n("span",{staticClass:"strut",staticStyle:{height:"0.68333em"}}),n("span",{staticClass:"strut bottom",staticStyle:{height:"0.76666em","vertical-align":"-0.08333em"}}),n("span",{staticClass:"base displaystyle textstyle uncramped"},[n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.13889em"}},[t._v("T")]),n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.13889em"}},[t._v("F")]),n("span",{staticClass:"mbin"},[t._v("−")]),n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.07847em"}},[t._v("I")]),n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.02778em"}},[t._v("D")]),n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.13889em"}},[t._v("F")]),n("span",{staticClass:"mrel"},[t._v("=")]),n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.13889em"}},[t._v("T")]),n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.13889em"}},[t._v("F")]),n("span",{staticClass:"mbin"},[t._v("∗")]),n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.07847em"}},[t._v("I")]),n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.02778em"}},[t._v("D")]),n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.13889em"}},[t._v("F")])])])])])]),t._v(" "),n("p",[t._v("主要思想：如果某个词或者短语在一篇文章中出现的TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用于分类")]),t._v(" "),n("p",[t._v("TF-IDF加权的各种形式常被搜索引擎应用，作为文件与用户查询之间相关程度的度量和评级")]),t._v(" "),n("h3",{attrs:{id:"词频（term-frequency，tf）"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#词频（term-frequency，tf）"}},[t._v("#")]),t._v(" 词频（Term Frequency，TF）")]),t._v(" "),n("p",[t._v("指的是某一个给定词语在该文件中出现的频率，这个数字是对词数的归一化，以防止偏向更长的文件")]),t._v(" "),n("p",[t._v("TF = 词语在文章中出现的次数/文章中全部词数")]),t._v(" "),n("h3",{attrs:{id:"逆文档频率（inverse-document-frequency，idf）"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#逆文档频率（inverse-document-frequency，idf）"}},[t._v("#")]),t._v(" 逆文档频率（Inverse Document Frequency，IDF）")]),t._v(" "),n("p",[t._v("是一个词语普遍重要性的度量，某一次与的IDF，可以由总文档数目除以包含该词语的文档数目，再将商取对数得到")]),t._v(" "),n("p",[n("span",{staticClass:"katex-display"},[n("span",{staticClass:"katex"},[n("span",{staticClass:"katex-mathml"},[n("math",[n("semantics",[n("mrow",[n("mi",[t._v("I")]),n("mi",[t._v("D")]),n("mi",[t._v("F")]),n("mo",[t._v("=")]),n("mi",[t._v("l")]),n("mi",[t._v("o")]),n("mi",[t._v("g")]),n("mo",[t._v("(")]),n("mfrac",[n("mrow",[n("mi",[t._v("N")]),n("mo",[t._v("+")]),n("mn",[t._v("1")])],1),n("mrow",[n("msub",[n("mi",[t._v("N")]),n("mrow",[n("mi",[t._v("i")])],1)],1),n("mo",[t._v("+")]),n("mn",[t._v("1")])],1)],1),n("mo",[t._v(")")])],1),n("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("IDF = log(\\frac{N+1}{N_{i}+1})\n")])],1)],1)],1),n("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[n("span",{staticClass:"strut",staticStyle:{height:"1.36033em"}}),n("span",{staticClass:"strut bottom",staticStyle:{height:"2.19633em","vertical-align":"-0.8360000000000001em"}}),n("span",{staticClass:"base displaystyle textstyle uncramped"},[n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.07847em"}},[t._v("I")]),n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.02778em"}},[t._v("D")]),n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.13889em"}},[t._v("F")]),n("span",{staticClass:"mrel"},[t._v("=")]),n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")]),n("span",{staticClass:"mord mathit"},[t._v("o")]),n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.03588em"}},[t._v("g")]),n("span",{staticClass:"mopen"},[t._v("(")]),n("span",{staticClass:"mord reset-textstyle displaystyle textstyle uncramped"},[n("span",{staticClass:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"}),n("span",{staticClass:"mfrac"},[n("span",{staticClass:"vlist"},[n("span",{staticStyle:{top:"0.686em"}},[n("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[n("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),n("span",{staticClass:"reset-textstyle textstyle cramped"},[n("span",{staticClass:"mord textstyle cramped"},[n("span",{staticClass:"mord"},[n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.10903em"}},[t._v("N")]),n("span",{staticClass:"vlist"},[n("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"-0.10903em"}},[n("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[n("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),n("span",{staticClass:"reset-textstyle scriptstyle cramped"},[n("span",{staticClass:"mord scriptstyle cramped"},[n("span",{staticClass:"mord mathit"},[t._v("i")])])])]),n("span",{staticClass:"baseline-fix"},[n("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[n("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])]),n("span",{staticClass:"mbin"},[t._v("+")]),n("span",{staticClass:"mord mathrm"},[t._v("1")])])])]),n("span",{staticStyle:{top:"-0.22999999999999998em"}},[n("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[n("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),n("span",{staticClass:"reset-textstyle textstyle uncramped frac-line"})]),n("span",{staticStyle:{top:"-0.677em"}},[n("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[n("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),n("span",{staticClass:"reset-textstyle textstyle uncramped"},[n("span",{staticClass:"mord textstyle uncramped"},[n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.10903em"}},[t._v("N")]),n("span",{staticClass:"mbin"},[t._v("+")]),n("span",{staticClass:"mord mathrm"},[t._v("1")])])])]),n("span",{staticClass:"baseline-fix"},[n("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[n("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])]),n("span",{staticClass:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"})]),n("span",{staticClass:"mclose"},[t._v(")")])])])])])]),t._v(" "),n("p",[n("span",{staticClass:"katex"},[n("span",{staticClass:"katex-mathml"},[n("math",[n("semantics",[n("mrow",[n("mi",[t._v("N")])],1),n("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("N")])],1)],1)],1),n("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[n("span",{staticClass:"strut",staticStyle:{height:"0.68333em"}}),n("span",{staticClass:"strut bottom",staticStyle:{height:"0.68333em","vertical-align":"0em"}}),n("span",{staticClass:"base textstyle uncramped"},[n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.10903em"}},[t._v("N")])])])]),t._v("表示文档集中文档总数，"),n("span",{staticClass:"katex"},[n("span",{staticClass:"katex-mathml"},[n("math",[n("semantics",[n("mrow",[n("msub",[n("mi",[t._v("N")]),n("mrow",[n("mi",[t._v("i")])],1)],1)],1),n("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("N_{i}")])],1)],1)],1),n("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[n("span",{staticClass:"strut",staticStyle:{height:"0.68333em"}}),n("span",{staticClass:"strut bottom",staticStyle:{height:"0.83333em","vertical-align":"-0.15em"}}),n("span",{staticClass:"base textstyle uncramped"},[n("span",{staticClass:"mord"},[n("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.10903em"}},[t._v("N")]),n("span",{staticClass:"vlist"},[n("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"-0.10903em"}},[n("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[n("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),n("span",{staticClass:"reset-textstyle scriptstyle cramped"},[n("span",{staticClass:"mord scriptstyle cramped"},[n("span",{staticClass:"mord mathit"},[t._v("i")])])])]),n("span",{staticClass:"baseline-fix"},[n("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[n("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])])])])]),t._v("表示文档集中包含词语"),n("span",{staticClass:"katex"},[n("span",{staticClass:"katex-mathml"},[n("math",[n("semantics",[n("mrow",[n("mi",[t._v("i")])],1),n("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("i")])],1)],1)],1),n("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[n("span",{staticClass:"strut",staticStyle:{height:"0.65952em"}}),n("span",{staticClass:"strut bottom",staticStyle:{height:"0.65952em","vertical-align":"0em"}}),n("span",{staticClass:"base textstyle uncramped"},[n("span",{staticClass:"mord mathit"},[t._v("i")])])])]),t._v("的文档数")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" math\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TF_IDF")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("pass")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("compute_tf")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" word_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bow"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        tf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        n "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bow"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" word"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" count "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" word_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("word"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" count "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" n\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" tf\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("compute_idf")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" word_dict_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n        计算IDF = log10((N+1)/(Ni+1))，如果每个文档中都存在某个词，则IDF=0\n        :param word_dict_list:\n        :return: IDF\n        """')]),t._v("\n        idf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fromkeys"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word_dict_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        N "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word_dict_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" word_dict "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" word_dict_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" word"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" count "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" word_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" count "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    idf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("word"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" word"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ni "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" idf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n           idf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("word"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" math"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("log10"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("N"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ni"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" idf\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("compute_tf_idf")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" idf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        tf_idfs "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" word"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tfval "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            tf_idfs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("word"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tfval"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("idf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("word"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" tf_idfs\n    \n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 有两个文档")]),t._v("\ndoc_a "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"The cat sat on my bed"')]),t._v("\ndoc_b "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"The dog sat on my knees"')]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 对两个文档分词")]),t._v("\nbow_a "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("set")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("doc_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nbow_b "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("set")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("doc_b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 统计每个文档的词典")]),t._v("\nword_set "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" bow_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("union"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bow_b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nword_dict_a "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("dict")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fromkeys"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word_set"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nword_dict_b "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("dict")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fromkeys"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word_set"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" word "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" bow_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    word_dict_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("word"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" word "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" bow_b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    word_dict_b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("word"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n    \n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 计算TF-IDF")]),t._v("\ntf_idf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TF_IDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntf_a "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf_idf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("compute_tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word_dict_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bow_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntf_b "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf_idf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("compute_tf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word_dict_b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bow_b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nidf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf_idf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("compute_idf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("word_dict_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" word_dict_b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntf_idf_a "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf_idf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("compute_tf_idf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" idf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntf_idf_b "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf_idf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("compute_tf_idf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf_b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" idf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataFrame"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("tf_idf_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tf_idf_b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("结果如下：")]),t._v(" "),n("div",{attrs:{align:"center"}},[n("img",{attrs:{src:a(621),width:"120%"}})]),t._v(" "),n("p",[t._v("其中文档1中的关键词是cat和bed；文档2中的关键词是knees和dog")])])}),[],!1,null,null,null);s.default=e.exports}}]);