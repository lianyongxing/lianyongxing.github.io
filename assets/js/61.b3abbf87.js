(window.webpackJsonp=window.webpackJsonp||[]).push([[61],{479:function(a,t,s){a.exports=s.p+"assets/img/9B95D33C-FE47-4396-9F25-18A0A668C6DB.665a4ef5.png"},674:function(a,t,s){"use strict";s.r(t);var r=s(44),e=Object(r.a)({},(function(){var a=this,t=a.$createElement,r=a._self._c||t;return r("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[r("h1",{attrs:{id:"tensorflow分布式训练"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#tensorflow分布式训练"}},[a._v("#")]),a._v(" Tensorflow分布式训练")]),a._v(" "),r("h2",{attrs:{id:"tensorflow分布式原理"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#tensorflow分布式原理"}},[a._v("#")]),a._v(" Tensorflow分布式原理")]),a._v(" "),r("p",[a._v("TF分布式实现中，需要对client、master、work提供在不同机器上的支持。数据量很大的情况下，单机进行深度学习训练，过于耗时，因此需要分布式进行训练，提高效率")]),a._v(" "),r("p",[r("img",{attrs:{src:s(479),alt:"665a4ef58e5c763e1caa67a85ebdf3ae"}})]),a._v(" "),r("p",[a._v("左图为单机架构，右图为多机架构")]),a._v(" "),r("h3",{attrs:{id:"单机训练模式"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#单机训练模式"}},[a._v("#")]),a._v(" 单机训练模式")]),a._v(" "),r("p",[a._v("单机多核计算例子")]),a._v(" "),r("p",[a._v("假设机器上有3个GPU和1个CPU，在单机多核进行训练的时，每次同时处理3个batch（同一时刻，每个GPU处理1个batch，一共有三个GPU），三个GPU计算完结果后，把结果传给CPU，由CPU进行求和平均，然后再把结果传给每个GPU，然后开始下一轮，下一轮中GPU再一次计算三个batch，并把结果给cpu，不断循环")]),a._v(" "),r("p",[a._v("上面描述的情况是"),r("strong",[a._v("同步")]),a._v("并行的过程")]),a._v(" "),r("p",[a._v("一个通俗一点的解释：")]),a._v(" "),r("p",[a._v("老师给小明布置了一个作业，内容是：有1000张纸，每张纸上有128道乘法题，将1000张纸上的乘法题的总和算出来。小明对加法比较擅长，小红、小刚、小王对乘法比较擅长，因此小明每次从1000张纸中拿出三张分给小红、小刚、小王三人，三人计算完后把结果反馈给小明，小明对三人的结果求和；完成一次后，小明再拿另外三张纸给三个人，不断循环，直到最后求出结果")]),a._v(" "),r("h3",{attrs:{id:"多机多核训练"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#多机多核训练"}},[a._v("#")]),a._v(" 多机多核训练")]),a._v(" "),r("p",[a._v("随着数据增加，模型参数越来越多，因此每一轮计算都是一个很长的过程，如果是单机16个GPU，也是一次处理16个batch，对于大数据来说，也需要漫长的时间，于是有了分布式学习算法或框架")]),a._v(" "),r("h4",{attrs:{id:"参数服务器"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#参数服务器"}},[a._v("#")]),a._v(" 参数服务器")]),a._v(" "),r("p",[a._v("当模型很大的时候，单个cpu进行加法也算不过来了，于是自然想到将参数分散到不同的机器上进行加法计算。借用小明的例子，单个小明计算不过来了，就在加入10个小明一起进行计算")]),a._v(" "),r("h4",{attrs:{id:"grpc"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#grpc"}},[a._v("#")]),a._v(" gRPC")]),a._v(" "),r("p",[a._v("Tensorflow分布式并行基于gRPC框架，其中包括一个master创建Session，多个worker执行计算图中的任务。")]),a._v(" "),r("p",[a._v("gRPC是一个RPC，也就是在本机上执行一个运算，例如")]),a._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[a._v("sum = add(a, b)\n")])])]),r("p",[a._v("这个过程是计算两个数的和，它调用了一个函数，然后返回一个结果，其实这个add方法是将参数a、b打包发送给服务器，然后服务器执行这个运算并返回一个值，最后由客户端接收到这个sum（本质上函数是在远程服务器上调用的）")]),a._v(" "),r("h4",{attrs:{id:"结构"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#结构"}},[a._v("#")]),a._v(" 结构")]),a._v(" "),r("p",[a._v("Cluster是Job的集合，Job是Task的集合")]),a._v(" "),r("p",[a._v("分布式深度学习框架中，一般Job由ParameterServer和Worker，一个保存参数，一个更新梯度")]),a._v(" "),r("p",[a._v("而每个Job又包含多个Task去执行，一般一台机器上运行一个Task")]),a._v(" "),r("h4",{attrs:{id:"模型并行和数据并行"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#模型并行和数据并行"}},[a._v("#")]),a._v(" 模型并行和数据并行")]),a._v(" "),r("p",[a._v("模型并行：")]),a._v(" "),r("p",[a._v("数据并行：不同worker节点获得一部分数据，进行计算")]),a._v(" "),r("h4",{attrs:{id:"同步更新和异步更新"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#同步更新和异步更新"}},[a._v("#")]),a._v(" 同步更新和异步更新")]),a._v(" "),r("p",[a._v("同步更新：每次梯度更新，要等所有分发出去的数据计算完成，当所有结果都返回后，再进行参数更新，这样可以使损失的下降比较稳定，但是由于要等所有节点都更新，因此效率会比较低")]),a._v(" "),r("p",[a._v("异步更新：所有的计算节点，各自算自己的，每次直接提取最新的参数进行梯度计算，这样的计算速度会加快，但是loss的下降不稳定")])])}),[],!1,null,null,null);t.default=e.exports}}]);