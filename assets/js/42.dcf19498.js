(window.webpackJsonp=window.webpackJsonp||[]).push([[42],{389:function(t,s,a){t.exports=a.p+"assets/img/pimodel.e01844c5.png"},390:function(t,s,a){t.exports=a.p+"assets/img/temporal_ensemble.afa8a35c.png"},641:function(t,s,a){"use strict";a.r(s);var e=a(44),i=Object(e.a)({},(function(){var t=this,s=t.$createElement,e=t._self._c||s;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"π-model-temporal-ensemble"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#π-model-temporal-ensemble"}},[t._v("#")]),t._v(" "),e("strong",[t._v("Π")]),t._v("-Model & Temporal Ensemble")]),t._v(" "),e("p",[t._v("介绍半监督学习算法"),e("strong",[t._v("Π")]),t._v("-Model和Temporal Ensemble")]),t._v(" "),e("h2",{attrs:{id:"π-model"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#π-model"}},[t._v("#")]),t._v(" "),e("strong",[t._v("Π")]),t._v("-Model")]),t._v(" "),e("div",{attrs:{align:"center"}},[e("img",{attrs:{src:a(389),width:"80%"}})]),t._v(" "),e("p",[t._v("pi-model在训练的时候会对每个样本"),e("span",{staticClass:"katex"},[e("span",{staticClass:"katex-mathml"},[e("math",[e("semantics",[e("mrow",[e("msub",[e("mi",[t._v("x")]),e("mi",[t._v("i")])],1)],1),e("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("x_i")])],1)],1)],1),e("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[e("span",{staticClass:"strut",staticStyle:{height:"0.43056em"}}),e("span",{staticClass:"strut bottom",staticStyle:{height:"0.58056em","vertical-align":"-0.15em"}}),e("span",{staticClass:"base textstyle uncramped"},[e("span",{staticClass:"mord"},[e("span",{staticClass:"mord mathit"},[t._v("x")]),e("span",{staticClass:"vlist"},[e("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),e("span",{staticClass:"reset-textstyle scriptstyle cramped"},[e("span",{staticClass:"mord mathit"},[t._v("i")])])]),e("span",{staticClass:"baseline-fix"},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])])])])]),t._v("进行随机增强，得到"),e("span",{staticClass:"katex"},[e("span",{staticClass:"katex-mathml"},[e("math",[e("semantics",[e("mrow",[e("msub",[e("mi",[t._v("x")]),e("mrow",[e("mi",[t._v("i")]),e("mn",[t._v("1")])],1)],1)],1),e("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("x_{i1}")])],1)],1)],1),e("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[e("span",{staticClass:"strut",staticStyle:{height:"0.43056em"}}),e("span",{staticClass:"strut bottom",staticStyle:{height:"0.58056em","vertical-align":"-0.15em"}}),e("span",{staticClass:"base textstyle uncramped"},[e("span",{staticClass:"mord"},[e("span",{staticClass:"mord mathit"},[t._v("x")]),e("span",{staticClass:"vlist"},[e("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),e("span",{staticClass:"reset-textstyle scriptstyle cramped"},[e("span",{staticClass:"mord scriptstyle cramped"},[e("span",{staticClass:"mord mathit"},[t._v("i")]),e("span",{staticClass:"mord mathrm"},[t._v("1")])])])]),e("span",{staticClass:"baseline-fix"},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])])])])]),t._v("和"),e("span",{staticClass:"katex"},[e("span",{staticClass:"katex-mathml"},[e("math",[e("semantics",[e("mrow",[e("msub",[e("mi",[t._v("x")]),e("mrow",[e("mi",[t._v("i")]),e("mn",[t._v("2")])],1)],1)],1),e("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("x_{i2}")])],1)],1)],1),e("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[e("span",{staticClass:"strut",staticStyle:{height:"0.43056em"}}),e("span",{staticClass:"strut bottom",staticStyle:{height:"0.58056em","vertical-align":"-0.15em"}}),e("span",{staticClass:"base textstyle uncramped"},[e("span",{staticClass:"mord"},[e("span",{staticClass:"mord mathit"},[t._v("x")]),e("span",{staticClass:"vlist"},[e("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),e("span",{staticClass:"reset-textstyle scriptstyle cramped"},[e("span",{staticClass:"mord scriptstyle cramped"},[e("span",{staticClass:"mord mathit"},[t._v("i")]),e("span",{staticClass:"mord mathrm"},[t._v("2")])])])]),e("span",{staticClass:"baseline-fix"},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])])])])]),t._v("；同时在训练的时候，在一个batch中同时加入labeled data和unlabeld data，得到batch1和batch2，首先对batch1进行预测得到logits1，再不更新梯度对时候对batch2进行预测得到logits2，对于labeled data计算其ce loss，作为supervised loss，对于两个batch之间的差异，计算mse loss，最终两个loss带权相加")]),t._v(" "),e("h3",{attrs:{id:"训练代码"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#训练代码"}},[t._v("#")]),t._v(" 训练代码")]),t._v(" "),e("p",[e("a",{attrs:{href:"https://github.com/lianyongxing/text-classification-nlp-pytorch/blob/main/train/train_pi_model.py",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://github.com/lianyongxing/text-classification-nlp-pytorch/blob/main/train/train_pi_model.py"),e("OutboundLink")],1)]),t._v(" "),e("h2",{attrs:{id:"temporal-ensemble"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#temporal-ensemble"}},[t._v("#")]),t._v(" Temporal Ensemble")]),t._v(" "),e("div",{attrs:{align:"center"}},[e("img",{attrs:{src:a(390),width:"80%"}})]),t._v(" "),e("p",[t._v("Temporal ensemble的核心思想在于，不同于Pi-Model中每个case在一次训练时，需要predict两次，得到两个logits，而是在时间（训练的不同epoch）上进行ensemble，将上一个epoch训练结果加入到当前epoch的训练loss计算当中，具体ensemble的方式是EMA（指数滑动平均）")]),t._v(" "),e("p",[t._v("具体实现为，在训练时loss分为supervised loss和unsupervised loss，supervised loss仍然为当前epoch输出的logits和label之间的cross entropy；unsupervised loss为当前epoch输出logits与之前所有epoch的ensemble结果的加权logits的MSE；最终两个loss加权求和（在前几个epoch，supervised loss比较重要，因此unsupervised loss的weight要ramp up逐渐增大）")]),t._v(" "),e("h3",{attrs:{id:"训练代码-2"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#训练代码-2"}},[t._v("#")]),t._v(" 训练代码")]),t._v(" "),e("p",[e("a",{attrs:{href:"https://github.com/lianyongxing/text-classification-nlp-pytorch/blob/main/train/train_temporal_ensembling.py",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://github.com/lianyongxing/text-classification-nlp-pytorch/blob/main/train/train_temporal_ensembling.py"),e("OutboundLink")],1)]),t._v(" "),e("h3",{attrs:{id:"references"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#references"}},[t._v("#")]),t._v(" References")]),t._v(" "),e("p",[e("a",{attrs:{href:"https://arxiv.org/abs/1610.02242",target:"_blank",rel:"noopener noreferrer"}},[t._v("Temporal Ensembling for Semi-Supervised Learning (ICLR2017)"),e("OutboundLink")],1)])])}),[],!1,null,null,null);s.default=i.exports}}]);