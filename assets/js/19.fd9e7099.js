(window.webpackJsonp=window.webpackJsonp||[]).push([[19],{426:function(e,t,n){e.exports=n.p+"assets/img/Untitled.d825cdf5.png"},427:function(e,t,n){e.exports=n.p+"assets/img/Untitled 1.3e4fe3a0.png"},428:function(e,t,n){e.exports=n.p+"assets/img/Untitled 2.f3ba4781.png"},429:function(e,t,n){e.exports=n.p+"assets/img/Untitled 3.f5b5b8ab.png"},430:function(e,t,n){e.exports=n.p+"assets/img/Untitled 4.1e9a62c7.png"},661:function(e,t,n){"use strict";n.r(t);var s=n(44),a=Object(s.a)({},(function(){var e=this,t=e.$createElement,s=e._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("h1",{attrs:{id:"mae：masked-autoencoders-are-scalable-vision-learners"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#mae：masked-autoencoders-are-scalable-vision-learners"}},[e._v("#")]),e._v(" MAE：Masked Autoencoders Are Scalable Vision Learners")]),e._v(" "),s("p",[s("strong",[e._v("带掩码的自回归编码器是可扩展的视觉学习器")])]),e._v(" "),s("ol",[s("li",[s("p",[e._v("He K, Chen X, Xie S, et al. Masked autoencoders are scalable vision learners[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 16000-16009.")]),e._v(" "),s("ol",[s("li",[e._v("前面vit采用了transformer的encoder架构用到cv中，核心是patch的切分以及大量标注数据的下游微调，精度比cnn会高；这篇文章MAE采用了"),s("strong",[e._v("无监督数据")]),e._v("进行预训练，将ViT扩展至没有标号的数据上，即"),s("strong",[e._v("cv版的完形填空")]),e._v("（vit主要是用大量有监督数据进行预训练，无监督的预训练做了很少效果不好；本文是大规模无监督数据上预训练；vit是输入整个图片，本文是encoder只输入非mask部分，并且少量的块为非mask）")]),e._v(" "),s("li",[e._v("训练的时候是用非对称的encoder-decoder结构，预测的时候只用encoder")]),e._v(" "),s("li",[e._v("作者考虑了到底是什么使得自编码的mask在nlp和cv效果不同，三个原因")])]),e._v(" "),s("div",{attrs:{align:"center"}},[s("img",{attrs:{src:n(426),width:"90%"}})]),e._v("\n                                       图1. MAE架构\n "),s("div",{attrs:{align:"center"}},[s("img",{attrs:{src:n(427),width:"90%"}})]),e._v(" "),s("p",[e._v("图2. MAE效果（大量mask，恢复图、原图）")]),e._v(" "),s("h2",{attrs:{id:"几个实验结果"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#几个实验结果"}},[e._v("#")]),e._v(" 几个实验结果")]),e._v(" "),s("div",{attrs:{align:"center"}},[s("img",{attrs:{src:n(428),width:"100%"}})]),e._v("\n 图3. 几个实验结果\n"),s("ol",[s("li",[e._v("end-to-end fine-tune时，不同block效果差不多；只训练最后线性分类层，block在8的时候最好")]),e._v(" "),s("li",[e._v("decoder width 512效果最好")]),e._v(" "),s("li",[e._v("encoder不加mask的patch时，效果更好，而且计算量少")]),e._v(" "),s("li",[e._v("重构的时候不同目标，复原pixel掩码部分，复原pixel掩码部分（每个pixel做归一化），PCA、dVAE token")]),e._v(" "),s("li",[e._v("按随机大小裁剪效果就很好，对数据增强不太敏感")]),e._v(" "),s("li",[e._v("最简单的随机采样效果最好")])]),e._v(" "),s("div",{attrs:{align:"center"}},[s("img",{attrs:{src:n(429),width:"90%"}})]),e._v(" "),s("p",[e._v("图4. 不同mask ratio的效果")]),e._v(" "),s("div",{attrs:{align:"center"}},[s("img",{attrs:{src:n(430),width:"100%"}})]),e._v(" "),s("p",[e._v("图5. 不同mask方式")])])])])}),[],!1,null,null,null);t.default=a.exports}}]);